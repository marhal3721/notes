## 1.设置Redis的慢日志阈值，只有超过阈值的命令才会被记录

```bash
# 设置慢日志的阈值为5毫秒，同时设置只保留最近1000条慢日志记录

## 命令执行超过5毫秒记录慢日志
127.0.0.1:6379> CONFIG SET slowlog-log-slower-than 5000
## 只保留最近1000条慢日志
127.0.0.1:6379> CONFIG SET slowlog-max-len 1000
```


## 2.查询最近5条慢日志
```bash
127.0.0.1:6379> SLOWLOG get 5

# 业务经常使用O(n)以上复杂度的命令，例如sort、sunion、zunionstore，或者在执行O(n)命令时操作的数据量比较大，Redis处理数据时会很耗时。
# 如果服务请求量并不大，但Redis实例的CPU使用率很高，很有可能是使用了复杂度高的命令导致的。
```

## 3.扫描大key

* 如果查询慢日志发现，并不是复杂度较高的命令导致的，例如都是SET、DELETE操作出现在慢日志记录中，那么就要怀疑是否存在Redis写入了大key的情况

```bash


# 在线上实例进行大key扫描时，Redis的QPS会突增，
# 为了降低扫描过程中对Redis的影响，需要控制扫描的频率，
# 使用-i参数控制，它表示扫描过程中每次扫描的时间间隔，单位是秒

redis-cli -h $host -p $port --bigkeys -i 0.01

# Redis在内部执行scan命令，遍历所有key，然后针对不同类型的key执行strlen、llen、hlen、scard、zcard来获取字符串的长度以及容器类型(list/dict/set/zset)的元素个数

```

## 集中过期
## 状况
* 平时在使用Redis时没有延时比较大的情况，但在某个时间点突然出现一波延时，而且报慢的时间点很有规律，例如某个整点，或者间隔多久就会发生一次
* Redis的主动过期的定时任务，也是在Redis主线程中执行的（如果在执行主动过期的过程中，出现了需要大量删除过期key的情况，那么在业务访问时，必须等这个过期任务执行结束，才可以处理业务请求。此时就会出现，业务访问延时增大的问题，最大延迟为25毫秒）

## Redis的过期策略
### 主动过期
* Redis内部维护一个定时任务，默认每隔100毫秒会从过期字典中随机取出20个key，删除过期的key，如果过期key的比例超过了25%，则继续获取20个key，删除过期的key，循环往复，直到过期key的比例下降到25%或者这次任务的执行耗时超过了25毫秒，才会退出循环

### 懒惰过期
* 只有当访问某个key时，才判断这个key是否已过期，如果已经过期，则从实例中删除

## 解决
* 开发
```bash

# 在集中过期时增加一个随机时间，把这些需要过期的key的时间打散

## 在过期时间点之后的5分钟内随机过期掉
redis.expireat(key, expire_time + random(300))
```

* 运维手段
	* 把Redis的各项运行数据监控起来，执行info可以拿到所有的运行数据
	* 重点关注expired_keys这一项，它代表整个实例到目前为止，累计删除过期key的数量
	* 在很短时间内这个指标出现突增时，需要及时报警出来，然后与业务报慢的时间点对比分析，确认时间是否一致，如果一致，则可以认为确实是因为这个原因导致的延迟增大

## 实例内存达到上限
 